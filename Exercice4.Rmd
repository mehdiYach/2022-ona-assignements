---
title: "Exercice 4"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1

```{r}
#install.packages('wru')
library(wru)
library(arrow)
library(lubridate)
library(tidyverse)
#install.packages('gender')
library(gender)
library(gridExtra)
library(ggplot2)
library(grid)
library(igraph)
library(ggraph)
```


```{r}
library(readr)

#install.packages("arrow")
library("arrow")

edges <- read_csv("C:/Users/Mehdi/Desktop/2022-ona-assignements/edges_sample.csv")

applications <- read_parquet("C:/Users/Mehdi/Desktop/2022-ona-assignements/app_data_sample.parquet")

```



``` {r}
# get list of unique first names
name_of_examiner = applications %>% distinct(examiner_name_first)
name_of_examiner

```
# Get Gender
``` {r}
library(dplyr)
gender = name_of_examiner %>% do(outcome = gender(.$examiner_name_first, method = "ssa")) %>% unnest(cols = c(outcome), keep_empty=TRUE) %>% 
  select(examiner_name_first = name, gender,proportion_female)

gender


```

## Joining and Cleaning 
```{r}
# keep only the name and the gender columns in the table
gender = gender %>% select(examiner_name_first, gender)

# Adding the gender to the previous data frame
applications = applications %>% left_join(gender, by = "examiner_name_first")

applications

```

# Race
``` {r}

surname = applications %>% distinct(surname = examiner_name_last) 

surname

```

``` {r}
race = predict_race(voter.file=surname, surname.only=T) %>% as_tibble()

# Get Race probability based on surname 

race = race %>% 
  mutate(max_proba_race = pmax( pred.his,pred.oth,pred.asi, pred.bla, pred.whi)) 

race = race %>% 
  mutate(race = case_when(
    max_proba_race == pred.bla ~ "Black",
    max_proba_race == pred.whi ~ "white",
    max_proba_race == pred.asi ~ "Asian",
    max_proba_race == pred.his ~ "Hispanic",
    max_proba_race == pred.oth ~ "Other",
    TRUE ~ NA_character_
  ))

race
``` 

``` {r}
# keeping only the race and the surname
race = race %>% select(surname,race)

#Joining to the data frame
applications = applications %>% left_join(race, by = c("examiner_name_last" = "surname"))
```


# Tenure

``` {r}

# get filling dates, start and end date and calculate the tenure
dates = applications %>% select(examiner_id, filing_date, appl_status_date) %>% mutate(start_date = ymd(filing_date), end_date = as_date( dmy_hms(appl_status_date) )) %>% group_by(examiner_id) %>% 
  summarise(
    earliest = min(start_date, na.rm = TRUE), 
    latest = max(end_date, na.rm = TRUE),
    tenure = interval(earliest, latest) %/% days(1)
    ) %>% filter(year(latest)<2018)

dates

```

``` {r}
# Join to data frame
applications = applications %>% left_join(dates, by = "examiner_id")
applications

```
# Get application duration

``` {r }
#Get the filling dates
dates_of_applications = applications %>%
  select(application_number, filing_date, appl_status_date) %>%
  mutate(start_date = ymd(filing_date), end_date = as_date(dmy_hms(appl_status_date))) %>%
  summarise( application_number = application_number,filed =start_date,decision = end_date,appl_days = interval(filed,decision) %/% days(1)) %>% filter(year(decision)<2018)

#Joining 
applications =  applications %>% left_join(dates_of_applications, by = "application_number")

head(applications)
```

# Dealing with missing values by imputations 

``` {r}
#Removing variables for which it's not interesting to input missing values

my_subset = applications %>% subset( select = -c(examiner_name_middle, latest, filing_date, abandon_date, earliest, decision, filed, appl_status_date, patent_issue_date, patent_number)) %>% drop_na(examiner_id)

#install.packages('mice')
require(mice)
md.pattern(my_subset)


```


``` {r}
# Set gender as factor to use the mice package
my_subset$gender = as.factor(my_subset$gender)
applications_2 = complete(mice(my_subset, m=3, maxit=3))

```
``` {r}


```
# Advice Network

``` {r}

# Get work group of examiners 
ex_art_unit = distinct(subset(applications_2, select = c(examiner_art_unit, examiner_id)))

# Add work group for the graphs
ex_art_unit$wg = substr(ex_art_unit$examiner_art_unit, 1,3)

# Merging for ego and alter

my_network = merge(x = edges, y = ex_art_unit, by.x = "ego_examiner_id", by.y = "examiner_id", all.x = TRUE)
my_network = my_network %>% rename(art_unit_ego = examiner_art_unit, wg_ego = wg)

my_network = merge(x = my_network, y = ex_art_unit, by.x = "alter_examiner_id", by.y = "examiner_id", all.x = TRUE)
my_network = my_network %>% rename(art_unit_alter = examiner_art_unit, wg_alter = wg)

my_network = drop_na(my_network)

# Ego Nodes vs alter Nodes
ego_nodes = subset(my_network, select=c(ego_examiner_id, art_unit_ego, wg_ego)) 

ego_nodes = ego_nodes %>% rename(examiner_id=ego_examiner_id,art_unit=art_unit_ego,work_group=wg_ego)

alter_nodes = subset(my_network, select=c(alter_examiner_id, art_unit_alter, wg_alter)) 

alter_nodes = alter_nodes %>% rename(examiner_id=alter_examiner_id,art_unit=art_unit_alter, work_group=wg_alter)

nodes = distinct(rbind(ego_nodes, alter_nodes)) %>% group_by(examiner_id) %>% summarise(examiner_id = first(examiner_id), art_unit = first(art_unit), work_group = first(work_group))

network = graph_from_data_frame(d=my_network, vertices=nodes, directed=TRUE)
network

my_degree = round(degree(network, v=V(network)),2)
my_betweenness = round(betweenness(network),2)
my_closeness = round(closeness(network),2)

V(network)$size = my_degree
V(network)$bet = my_betweenness
V(network)$clo = my_closeness
V(network)$color = nodes$art_unit



```

``` {r}

#Merge the centralities 
centrality = data.frame( round( cbind(my_degree, my_betweenness, my_closeness), 2) )

centrality = cbind(examiner_id = rownames(centrality),centrality)
nbr_rows = nrow(centralities)
rownames(centralities) = (1:nbr_rows)

#Merge on applications data frame
applications_3 = merge(x=applications_2, y=centrality, by="examiner_id", all.x=TRUE)

applications_3 = drop_na(applications_3)

```

# Modeling

## Model 1: Relationship between the centrality measures and the target variable: application days

Control variables: Race, Gender, Tenure
```{r}
# Setting the reference level
lm_1 = lm(appl_days ~ my_degree+ my_betweenness+ my_closeness + race + gender + tenure , data=applications_3)
summary(lm_1)


```
### Interpretation:

All the variables coefficients seems to be very significant (very low p-values). The race White coefficient can also be considered as significant at 95% confidence level. 

The average application process takes around 415 days for an asian female.

The following points are noted:

    - When an examiner seeks advices from a new examiner, which is adding one unit to the centrality degree, the application processing time decreases by 0.08 days, which is approximately 2 hours.
    
    - When the betweeness score is increased by one unit, meaning that the amount of influence an examiner has over the flow of information in the network increases by 1, the processing time also increases by 0.009, whcih is 13 minutes.
    
    - Increasing by one unit the closeness score of an examiner, which is how fast the flow of information goes through the node, increases the processing time by 34 days. This means that the shorter is the distance between this examiner and the rest of them, the longer the processing time will be.
    
    - If the examiner is black, hispanic or white, the application will take respectively 30, 101 and 5 additional days than for an asian examiner.
    
    - If the examiner is a male, it will take 32 more days than for a female.
    
    - Increasing the tenure day by one unit also increases the processing time by 0.1 days, which is approximately 2.5 hours.



## Model 2: Interactions between centralities and gender
``` {r}

lm_3 = lm(appl_days ~ my_degree+ my_betweenness+ my_closeness + race + gender + tenure + gender*my_degree + gender*my_betweenness + gender*my_closeness , data=applications_3)
summary(lm_3)

```
### Interpretation:

All the variables coefficients seems to be very significant (very low p-values) except the interaction term of a male examiner betweeness degree, a hispanic examiner, and the closeness. 

The interactions terms shows the following points that increasing the centrality degree or the closeness degree of a male examiner by one unit leads to an increase in the processing time of respectively 0.4 and 50 days comparing to a female examiner. 
This shows that a female that is very well placed to influence the whole network will see her processing time be 50 days shorter than for a male with this same characteristic. 


Also, according to this new model, we have the following points:

    - The average application process takes around 465 days for an asian female.

    - When an examiner seeks advices from a new examiner, which is adding one unit to the centrality degree, the application processing time decreases by 0.3 days.
    
    - When the betweeness score is increased by one unit, meaning that the amount of influence an examiner has over the flow of information in the network increases by 1, the processing time also increases by 0.009 days.

    - If the examiner is black, hispanic or white, the application will take respectively 26, 106 and 4.5 additional days than for an asian examiner.
    
    - If the examiner is a male, it will take 31 less days than for a female.
    
    - Increasing the tenure day by one unit also increases the processing time by 0.2 days, which is approximately 5 hours.
    

# Additional discussion and implications

Within the organization, it seems like the asian examiners have the shortest processing time while it takes 106 additionnal days for the hispanic examiners, which is significantly greater. Asian examiners seems to benefit more from the processing time.

The last model shows that women that are very well placed to influence the network (measured by the closeness) will see there application processing time shortened by 50 days compared to a male in the same position.  

